{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/users/trifo/desktop/MUMT 203 AMT/package_aa'\n",
    "tie_list = []\n",
    "# count = 0\n",
    "for idx, dirname in enumerate(os.listdir(path)):\n",
    "    # print(dirname)\n",
    "    for filename in os.listdir(f'{path}/{dirname}'):\n",
    "        if filename.endswith(\".semantic\"):\n",
    "            f = open(f'{path}/{dirname}/{filename}', 'r')\n",
    "            # read = f.read().split()\n",
    "            total = f.read()\n",
    "            if \"tie\" in total:\n",
    "                tie_list.append(filename.split('.')[0])\n",
    "            # print(read)\n",
    "            # for j in read:\n",
    "            #     if \"keySignature\" in j:\n",
    "            #         y_sequences.add(j)\n",
    "            # y_sequences.append(f.read().split())\n",
    "# print(y_sequences)\n",
    "print(tie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000051661-1_1_2'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tie_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'C:/users/trifo/desktop/AMT/test_order.json'\n",
    "f = open(json_path)\n",
    "order = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000051650-1_1_1.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(order)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load('C:/Users/trifo/Desktop/AMT/batches/y/batch_1/000051653-1_2_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 959,  613,  166,  964,  350,  350,  975,  745,  169,  403,  832,\n",
       "       1031, 1031,  975], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tie_list:\n",
    "    order.pop(i + '.wav', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/users/trifo/desktop/AMT/no_tie.json', 'w') as f:\n",
    "    json.dump(order, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tie = json.load(open('C:/users/trifo/desktop/AMT/no_tie.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:/users/trifo/desktop/AMT/no_tie.json')\n",
    "order = json.load(f)\n",
    "mapping = open('C:/users/trifo/desktop/AMT/w2i_aav2.json')\n",
    "w2i = json.load(mapping)\n",
    "sorted_order = list(sorted(order.items(), key=lambda item: item[1], reverse=True))\n",
    "max_len = 0\n",
    "# for img in sorted_order:\n",
    "#     name = img[0].split('.')[0]\n",
    "#     f_in = open(f'C:/users/trifo/desktop/MUMT 203 AMT/package_aa/{name}/{name}.semantic', 'r')\n",
    "#     notes = [w2i[note] for note in f_in.read().split() if not ('barline' in note or 'keySignature' in note or 'clef' in note or 'timeSignature' in note)]\n",
    "#     if len(notes) > max_len:\n",
    "#         max_len = len(notes)\n",
    "# max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPoolAcrossTime(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GlobalMaxPoolAcrossTime, self).__init__(**kwargs)\n",
    "\n",
    "    # (Batch_size, time, y, x, channels) -> (Batch_size, 1, y, x, channels)\n",
    "    def call(self, inputs):\n",
    "        shape = inputs.shape[2]\n",
    "        if not inputs.shape[2]:\n",
    "            shape = 64\n",
    "        pixels = math.floor(shape/64)\n",
    "        # pixels = int(shape/64)\n",
    "        # print('pixels')\n",
    "        # print('pixels',pixels)\n",
    "        pool_list = []\n",
    "        for i in range(0, pixels*64, pixels):\n",
    "            pool_list.append(K.max(inputs[:,:,i:i+pixels], axis=2, keepdims=True))\n",
    "        # return tensorflow.keras.backend.max(inputs, axis=1, keepdims=True)\n",
    "        # print(len(pool_list))\n",
    "        return layers.Concatenate(axis=2)(pool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, None, 64), dtype=tf.float32, name=None), name='conv2d_7/Relu:0', description=\"created by layer 'conv2d_7'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, None, 64), dtype=tf.float32, name=None), name='max_pooling2d_4/MaxPool:0', description=\"created by layer 'max_pooling2d_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, None, 128), dtype=tf.float32, name=None), name='conv2d_8/Relu:0', description=\"created by layer 'conv2d_8'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 128), dtype=tf.float32, name=None), name='max_pooling2d_5/MaxPool:0', description=\"created by layer 'max_pooling2d_5'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 256), dtype=tf.float32, name=None), name='conv2d_9/Relu:0', description=\"created by layer 'conv2d_9'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 256), dtype=tf.float32, name=None), name='conv2d_10/Relu:0', description=\"created by layer 'conv2d_10'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 256), dtype=tf.float32, name=None), name='max_pooling2d_6/MaxPool:0', description=\"created by layer 'max_pooling2d_6'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='batch_normalization_2/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='conv2d_12/Relu:0', description=\"created by layer 'conv2d_12'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='batch_normalization_3/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_3'\")\n",
      "pool_6: KerasTensor(type_spec=TensorSpec(shape=(None, 2, None, 512), dtype=tf.float32, name=None), name='max_pooling2d_7/MaxPool:0', description=\"created by layer 'max_pooling2d_7'\")\n",
      "global_pool: KerasTensor(type_spec=TensorSpec(shape=(None, 2, 64, 512), dtype=tf.float32, name=None), name='global_max_pool_across_time_1/concatenate/concat:0', description=\"created by layer 'global_max_pool_across_time_1'\")\n",
      "conv_7: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 63, 512), dtype=tf.float32, name=None), name='conv2d_13/Relu:0', description=\"created by layer 'conv2d_13'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 63, 512), dtype=tf.float32, name=None), name='lambda_1/Squeeze:0', description=\"created by layer 'lambda_1'\")\n"
     ]
    }
   ],
   "source": [
    "# input with shape of height=32 and width=128 \n",
    "inputs = Input(shape=(128,None,1))\n",
    "# print(inputs.shape[0]/2)\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "print(conv_1)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 1))(conv_1)\n",
    "print(pool_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "print(conv_2)\n",
    "\n",
    "pool_2 = MaxPool2D(pool_size=(2, 1))(conv_2)\n",
    "print(pool_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "print(conv_3)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "print(conv_4)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(4, 1))(conv_4)\n",
    "print(pool_4)\n",
    "\n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "print(conv_5)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    "print(batch_norm_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "print(conv_6)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "print(batch_norm_6)\n",
    "pool_6 = MaxPool2D(pool_size=(4, 1))(batch_norm_6)\n",
    "print(f'pool_6: {pool_6}')\n",
    "\n",
    "global_pool = GlobalMaxPoolAcrossTime()(pool_6)\n",
    "print(f'global_pool: {global_pool}')\n",
    "\n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(global_pool)\n",
    "print(f'conv_7: {conv_7}')\n",
    "\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "print(squeezed)\n",
    " \n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(len(w2i)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_gen():\n",
    "    path_x = 'D:/AMT/batches/aa_piano/validate_x'\n",
    "    path_y = 'D:/AMT/batches/aa_piano/validate_y'\n",
    "    for idx, dirname in enumerate(os.listdir(path_x)):\n",
    "        validate_img = []\n",
    "        validate_txt = []\n",
    "        validate_input_length = []\n",
    "        validate_label_length = []\n",
    "        # max_label_len = 0\n",
    "        for filename in os.listdir(f'{path_x}/{dirname}'):\n",
    "            # Images\n",
    "            img = cv2.imread(f'{path_x}/{dirname}/{filename}', cv2.IMREAD_GRAYSCALE)\n",
    "            # img = img.reshape(img.shape[1], img.shape[0])\n",
    "            # (W, H) --> (W, H, 1)\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            # Normalize image\n",
    "            img = img / 255.\n",
    "            validate_img.append(img)\n",
    "\n",
    "            # Text Targets\n",
    "            text = np.load(f'{path_y}/{dirname}/{filename}'.split('.')[0] + '.npy')\n",
    "            # if len(text) > max_label_len:\n",
    "            #     max_label_len = len(text)\n",
    "            validate_txt.append(text)\n",
    "            validate_label_length.append(len(text))\n",
    "            validate_input_length.append(63)\n",
    "        validate_padded_txt = pad_sequences(validate_txt, padding='post', maxlen=50)\n",
    "\n",
    "        yield np.array(validate_img), np.array(validate_padded_txt), np.array(validate_input_length), np.array(validate_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val_gen()\n",
    "valid_img, valid_padded_txt, valid_input_length, valid_label_length = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    }
   ],
   "source": [
    "# load the saved best model weights\n",
    "act_model.load_weights('best_model.hdf5')\n",
    "# act_model.load_weights('best_model.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "# img = cv2.imread('D:/AMT/batches/aa_piano/validate_x/batch_10/000125088-24_1_1.png', cv2.IMREAD_GRAYSCALE)\n",
    "# img = np.expand_dims(img, axis=2)\n",
    "# img = np.expand_dims(img, axis=0)\n",
    "# print(img.shape)\n",
    "# # Normalize image\n",
    "# img = img / 255.\n",
    "prediction = act_model.predict(valid_img[:5])\n",
    "\n",
    "# prediction = act_model.predict(img)\n",
    "\n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=False)[0][0])\n",
    "\n",
    "i2w = json.load(open('C:/Users/trifo/Desktop/AMT/i2w_aav2.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[820,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [820,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [820,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [820,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [820,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text =  note-C5_whole, note-G4_whole, note-A4_whole, note-E4_whole, note-F4_whole, note-G4_whole, note-C4_half, note-D4_half, note-E4_half, note-F4_half, note-G4_half, note-A4_half, note-B4_half, note-C5_half, \n",
      "\n",
      "predicted text = note-D5_eighth, \n",
      "\n",
      "original_text =  note-G3_whole, note-G3_half, note-G3_half, note-G3_whole, note-G3_whole, note-G3_half, note-G3_half, note-G3_half, note-G3_half, note-F#3_half., note-E3_quarter, note-D3_half., note-E3_eighth, note-F#3_eighth, note-G3_double_whole, multirest-1, \n",
      "\n",
      "predicted text = note-D5_eighth, \n",
      "\n",
      "original_text =  note-D4_double_whole, note-A4_whole, rest-half, note-A4_half, note-C5_whole, note-Bb4_half, note-A4_half, note-A4_quarter, note-G4_quarter, note-F4_half, note-E4_whole, rest-half, note-E4_half, note-F4_half., note-E4_quarter, \n",
      "\n",
      "predicted text = note-D5_eighth, \n",
      "\n",
      "original_text =  note-A4_whole, note-Bb4_whole, note-A4_whole, note-G4_whole, note-A4_whole, note-D4_whole, note-F4_whole, note-G4_whole, note-A4_whole, note-Bb4_whole, \n",
      "\n",
      "predicted text = note-D5_eighth, \n",
      "\n",
      "original_text =  rest-whole, note-F4_whole, note-F4_half, note-F4_half, note-G4_half, note-G4_half, note-A4_whole, note-F4_half, note-F4_half, note-F4_half, note-A4_half, note-Bb4_whole, note-Bb4_half, note-A4_half, note-G4_whole, \n",
      "\n",
      "predicted text = note-D5_eighth, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", end = '')\n",
    "    for j in valid_padded_txt[i]:\n",
    "        if j != 0:\n",
    "            print(i2w[str(j)], end = ', ')\n",
    "    print('\\n')\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(i2w[str(int(p))], end = ', ')    \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429e7ccc7c3719b21c1bf706142e8020d560237833d6c035ca6dea55fe035c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
