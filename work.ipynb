{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44084\n",
      "39862\n"
     ]
    }
   ],
   "source": [
    "order_ab = json.load(open('order_ab.json'))\n",
    "print(len(order_ab))\n",
    "path = 'C:/users/trifo/desktop/MUMT 203 AMT/package_ab'\n",
    "tie_list = []\n",
    "# count = 0\n",
    "for idx, dirname in enumerate(os.listdir(path)):\n",
    "    # print(dirname)\n",
    "    for filename in os.listdir(f'{path}/{dirname}'):\n",
    "        if filename.endswith(\".semantic\"):\n",
    "            f = open(f'{path}/{dirname}/{filename}', 'r')\n",
    "            # read = f.read().split()\n",
    "            total = f.read()\n",
    "            if \"tie\" in total:\n",
    "                # tie_list.append(filename.split('.')[0])\n",
    "                order_ab.pop(dirname + '.wav', None)\n",
    "            # print(read)\n",
    "            # for j in read:\n",
    "            #     if \"keySignature\" in j:\n",
    "            #         y_sequences.add(j)\n",
    "            # y_sequences.append(f.read().split())\n",
    "# print(y_sequences)\n",
    "print(len(order_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_aa = json.load(open('w2i_aav3.json'))\n",
    "order_ab = json.load(open('w2i_abv3.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1407\n",
    "for i in order_ab:\n",
    "    if i not in order_aa:\n",
    "        print(i)\n",
    "        order_aa[i] = idx\n",
    "        idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(order_aa, open('w2i_all.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w = {str(order_aa[k]): k for k in order_aa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'note-A#5_quarter.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w['6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_aa['note-A#5_quarter.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(i2w, open('i2w_all.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "deep = copy.deepcopy(order_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in deep:\n",
    "    if order_ab[i] > 1500:\n",
    "        order_ab.pop(i, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39559\n"
     ]
    }
   ],
   "source": [
    "print(len(order_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_aa = json.load(open('no_tie.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39054"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_aa = copy.deepcopy(order_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in deep_aa:\n",
    "    if order_aa[i] > 1500:\n",
    "        order_aa.pop(i, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(order_ab, open('no_tie_ab.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000051661-1_1_2'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tie_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'C:/users/trifo/desktop/AMT/test_order.json'\n",
    "f = open(json_path)\n",
    "order = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000051650-1_1_1.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(order)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load('C:/Users/trifo/Desktop/AMT/batches/y/batch_1/000051653-1_2_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 959,  613,  166,  964,  350,  350,  975,  745,  169,  403,  832,\n",
       "       1031, 1031,  975], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tie_list:\n",
    "    order.pop(i + '.wav', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/users/trifo/desktop/AMT/no_tie.json', 'w') as f:\n",
    "    json.dump(order, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tie = json.load(open('C:/users/trifo/desktop/AMT/no_tie.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "29\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "38\n",
      "41\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order_aa = json.load(open('no_tie_aa.json'))\n",
    "order_ab = json.load(open('no_tie_ab.json'))\n",
    "order_all = order_aa | order_ab\n",
    "mapping = open('C:/users/trifo/desktop/AMT/w2i_all.json')\n",
    "w2i = json.load(mapping)\n",
    "sorted_order = list(sorted(order_ab.items(), key=lambda item: item[1], reverse=True))\n",
    "max_len = 0\n",
    "for img in sorted_order:\n",
    "    name = img[0].split('.')[0]\n",
    "    if img[0] in order_ab:\n",
    "        f_in = open(f'C:/users/trifo/desktop/MUMT 203 AMT/package_ab/{name}/{name}.semantic', 'r')\n",
    "    # else:\n",
    "    #     f_in = open(f'C:/users/trifo/desktop/MUMT 203 AMT/package_ab/{name}/{name}.semantic', 'r')\n",
    "    notes = [w2i[note] for note in f_in.read().split() if not ('barline' in note or 'keySignature' in note or 'clef' in note or 'timeSignature' in note)]\n",
    "    if len(notes) > max_len:\n",
    "        max_len = len(notes)\n",
    "        print(max_len)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39559"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPoolAcrossTime(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GlobalMaxPoolAcrossTime, self).__init__(**kwargs)\n",
    "\n",
    "    # (Batch_size, time, y, x, channels) -> (Batch_size, 1, y, x, channels)\n",
    "    def call(self, inputs):\n",
    "        shape = inputs.shape[2]\n",
    "        if not inputs.shape[2]:\n",
    "            shape = 64\n",
    "        pixels = math.floor(shape/64)\n",
    "        # pixels = int(shape/64)\n",
    "        # print('pixels')\n",
    "        # print('pixels',pixels)\n",
    "        pool_list = []\n",
    "        for i in range(0, pixels*64, pixels):\n",
    "            pool_list.append(K.max(inputs[:,:,i:i+pixels], axis=2, keepdims=True))\n",
    "        # return tensorflow.keras.backend.max(inputs, axis=1, keepdims=True)\n",
    "        # print(len(pool_list))\n",
    "        return layers.Concatenate(axis=2)(pool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i = json.load(open('C:/Users/trifo/Desktop/AMT/w2i_all.json', 'r'))\n",
    "len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, None, 64), dtype=tf.float32, name=None), name='conv2d/Relu:0', description=\"created by layer 'conv2d'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, None, 64), dtype=tf.float32, name=None), name='max_pooling2d/MaxPool:0', description=\"created by layer 'max_pooling2d'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 64, None, 128), dtype=tf.float32, name=None), name='conv2d_1/Relu:0', description=\"created by layer 'conv2d_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 128), dtype=tf.float32, name=None), name='max_pooling2d_1/MaxPool:0', description=\"created by layer 'max_pooling2d_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 256), dtype=tf.float32, name=None), name='conv2d_2/Relu:0', description=\"created by layer 'conv2d_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, None, 256), dtype=tf.float32, name=None), name='conv2d_3/Relu:0', description=\"created by layer 'conv2d_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16, None, 256), dtype=tf.float32, name=None), name='max_pooling2d_2/MaxPool:0', description=\"created by layer 'max_pooling2d_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16, None, 512), dtype=tf.float32, name=None), name='conv2d_4/Relu:0', description=\"created by layer 'conv2d_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='max_pooling2d_3/MaxPool:0', description=\"created by layer 'max_pooling2d_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='conv2d_5/Relu:0', description=\"created by layer 'conv2d_5'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, None, 512), dtype=tf.float32, name=None), name='max_pooling2d_3/MaxPool:0', description=\"created by layer 'max_pooling2d_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, None, 512), dtype=tf.float32, name=None), name='conv2d_6/Relu:0', description=\"created by layer 'conv2d_6'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, None, 512), dtype=tf.float32, name=None), name='batch_normalization/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, None, 512), dtype=tf.float32, name=None), name='conv2d_7/Relu:0', description=\"created by layer 'conv2d_7'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, None, 512), dtype=tf.float32, name=None), name='batch_normalization_1/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1'\")\n",
      "pool_7: KerasTensor(type_spec=TensorSpec(shape=(None, 2, None, 512), dtype=tf.float32, name=None), name='max_pooling2d_5/MaxPool:0', description=\"created by layer 'max_pooling2d_5'\")\n",
      "conv_7: KerasTensor(type_spec=TensorSpec(shape=(None, 1, None, 512), dtype=tf.float32, name=None), name='conv2d_8/Relu:0', description=\"created by layer 'conv2d_8'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 512), dtype=tf.float32, name=None), name='lambda/Squeeze:0', description=\"created by layer 'lambda'\")\n"
     ]
    }
   ],
   "source": [
    "# input with shape of height=32 and width=128 \n",
    "inputs = Input(shape=(128,None,1))\n",
    "# print(inputs.shape[0]/2)\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "print(conv_1)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
    "print(pool_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "print(conv_2)\n",
    "\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2))(conv_2)\n",
    "print(pool_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "print(conv_3)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "print(conv_4)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 2))(conv_4)\n",
    "print(pool_4)\n",
    "\n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "print(conv_5)\n",
    "\n",
    "pool_5 = MaxPool2D(pool_size=(2, 1))(conv_5)\n",
    "print(pool_5)\n",
    "\n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_5)\n",
    "print(conv_6)\n",
    "\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(conv_6)\n",
    "print(pool_5)\n",
    "\n",
    "conv_7 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_6)\n",
    "print(conv_7)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_7)\n",
    "print(batch_norm_5)\n",
    " \n",
    "conv_8 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "print(conv_8)\n",
    "batch_norm_6 = BatchNormalization()(conv_8)\n",
    "print(batch_norm_6)\n",
    "pool_7 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "print(f'pool_7: {pool_7}')\n",
    "\n",
    "conv_9 = Conv2D(512, (2,2), activation = 'relu')(pool_7)\n",
    "print(f'conv_7: {conv_9}')\n",
    "\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_9)\n",
    "print(squeezed)\n",
    " \n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(len(w2i)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_gen():\n",
    "    path_x = 'D:/AMT/all/batches/marimba/validate_x'\n",
    "    path_y = 'D:/AMT/all/batches/marimba/validate_y'\n",
    "    batch_size = 16\n",
    "    all_files = os.listdir(path_x)\n",
    "    for idx in range(len(all_files)):\n",
    "        training_img = []\n",
    "        training_txt = []\n",
    "        train_input_length = []\n",
    "        train_label_length = []\n",
    "        mini = mini = all_files[idx: idx+batch_size]\n",
    "        for filename in mini:\n",
    "            # Images\n",
    "            img = cv2.imread(f'{path_x}/{filename}', cv2.IMREAD_GRAYSCALE)\n",
    "            # img = img.reshape(img.shape[1], img.shape[0])\n",
    "            # (W, H) --> (W, H, 1)\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            # Normalize image\n",
    "            img = img / 255.\n",
    "            training_img.append(img)\n",
    "\n",
    "            # Text Targets\n",
    "            text = np.load(f'{path_y}/{filename}'.split('.')[0] + '.npy')\n",
    "            # if len(text) > max_label_len:\n",
    "            #     max_label_len = len(text)\n",
    "            training_txt.append(text)\n",
    "            train_label_length.append(len(text))\n",
    "            train_input_length.append(63)\n",
    "\n",
    "        train_padded_txt = pad_sequences(training_txt, padding='post', maxlen=51)\n",
    "\n",
    "        yield np.array(training_img), np.array(train_padded_txt), np.array(train_input_length), np.array(train_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val_gen()\n",
    "act_model.load_weights('model_weights_copy.h5')\n",
    "# valid_img, valid_padded_txt, valid_input_length, valid_label_length = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20312/1918577870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mvalid_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_padded_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_input_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_label_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nFirst batch | Shape {valid_img.shape[2]}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20312/3082530348.py\u001b[0m in \u001b[0;36mval_gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# img = img.reshape(img.shape[1], img.shape[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# (W, H) --> (W, H, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;31m# Normalize image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trifo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[0mout_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[0mshape_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trifo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[1;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m     \u001b[1;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trifo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m     \u001b[1;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    valid_img, valid_padded_txt, valid_input_length, valid_label_length = next(val)\n",
    "    prediction = act_model.predict(valid_img[:3])\n",
    "    print(f\"\\nFirst batch | Shape {valid_img.shape[2]}\\n\")\n",
    "    \n",
    "    # use CTC decoder\n",
    "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], beam_width=500,\n",
    "                            greedy=False)[0][0])\n",
    "    i = 0\n",
    "    for x in out:\n",
    "        print(\"original_text =  \", end = '')\n",
    "        for j in valid_padded_txt[i]:\n",
    "            if j != 0:\n",
    "                print(i2w[str(j)], end = ', ')\n",
    "        print('\\n')\n",
    "        print(\"predicted text = \", end = '')\n",
    "        for p in x:  \n",
    "            if int(p) != -1:\n",
    "                print(i2w[str(p)], end = ', ')       \n",
    "        print('\\n')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 634ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the saved best model weights\n",
    "act_model.load_weights('my_model_weights.h5')\n",
    "# act_model.load_weights('best_model.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "# img = cv2.imread('D:/AMT/batches/aa_piano/validate_x/batch_10/000125088-24_1_1.png', cv2.IMREAD_GRAYSCALE)\n",
    "# img = np.expand_dims(img, axis=2)\n",
    "# img = np.expand_dims(img, axis=0)\n",
    "# print(img.shape)\n",
    "# # Normalize image\n",
    "# img = img / 255.\n",
    "prediction = act_model.predict(valid_img[:5])\n",
    "\n",
    "# prediction = act_model.predict(img)\n",
    "\n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], beam_width=500,\n",
    "                         greedy=True)[0][0])\n",
    "\n",
    "i2w = json.load(open('C:/Users/trifo/Desktop/AMT/i2w_all.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [356,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [356,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [356,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "       [356,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text =  note-Bb5_quarter, note-Eb5_eighth, note-Bb5_eighth, note-C6_eighth, note-Bb5_eighth, note-Ab5_eighth, note-Ab5_eighth, rest-sixteenth, note-Ab5_sixteenth, note-G5_sixteenth, note-Ab5_sixteenth, note-Bb5_sixteenth, note-Ab5_sixteenth, note-G5_sixteenth, note-Ab5_sixteenth, \n",
      "\n",
      "predicted text = \n",
      "\n",
      "original_text =  multirest-10, note-Bb4_quarter, note-Eb4_eighth, note-Eb5_eighth, note-Eb5_eighth, note-C5_eighth, note-Ab4_eighth, note-Ab4_eighth, rest-quarter, rest-quarter, note-F5_quarter, note-Eb5_eighth., note-C5_sixteenth, note-Bb4_eighth., note-Ab4_sixteenth, note-Ab4_eighth, note-G4_eighth, rest-quarter, \n",
      "\n",
      "predicted text = rest-quarter, \n",
      "\n",
      "original_text =  multirest-14, rest-quarter, rest-eighth, rest-quarter, note-G4_eighth, note-C5_quarter, rest-eighth, rest-quarter, rest-eighth, rest-quarter, note-C5_eighth, note-E5_quarter, note-C5_eighth, note-A4_quarter, note-A4_eighth, rest-quarter, rest-eighth, \n",
      "\n",
      "predicted text = rest-quarter, \n",
      "\n",
      "original_text =  multirest-4, rest-half, note-G4_eighth, note-G4_sixteenth, note-G4_sixteenth, note-G4_eighth, note-A4_eighth, note-B4_eighth, note-Bb4_eighth, rest-eighth, note-Bb4_eighth, note-Bb4_eighth, note-Bb4_eighth, note-A4_eighth, note-Bb4_eighth, note-G4_quarter, \n",
      "\n",
      "predicted text = rest-quarter, \n",
      "\n",
      "original_text =  multirest-23, rest-quarter, rest-eighth, note-Bb4_eighth, note-Bb4_quarter., note-G4_eighth, note-Eb5_quarter., note-D5_eighth, note-C5_eighth, note-C5_eighth, rest-quarter, \n",
      "\n",
      "predicted text = rest-quarter, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", end = '')\n",
    "    for j in valid_padded_txt[i]:\n",
    "        if j != 0:\n",
    "            print(i2w[str(j)], end = ', ')\n",
    "    print('\\n')\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(i2w[str(int(p))], end = ', ')    \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429e7ccc7c3719b21c1bf706142e8020d560237833d6c035ca6dea55fe035c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
