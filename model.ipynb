{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen():\n",
    "    path_x = 'D:/AMT/all/batches/marimba/x'\n",
    "    path_y = 'D:/AMT/all/batches/marimba/y'\n",
    "    for idx, dirname in enumerate(os.listdir(path_x)):\n",
    "        training_img = []\n",
    "        training_txt = []\n",
    "        train_input_length = []\n",
    "        train_label_length = []\n",
    "        for filename in os.listdir(f'{path_x}/{dirname}'):\n",
    "            # Images\n",
    "            img = cv2.imread(f'{path_x}/{dirname}/{filename}', cv2.IMREAD_GRAYSCALE)\n",
    "            # img = img.reshape(img.shape[1], img.shape[0])\n",
    "            # (W, H) --> (W, H, 1)\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            # Normalize image\n",
    "            img = img / 255.\n",
    "            training_img.append(img)\n",
    "\n",
    "            # Text Targets\n",
    "            text = np.load(f'{path_y}/{dirname}/{filename}'.split('.')[0] + '.npy')\n",
    "            # if len(text) > max_label_len:\n",
    "            #     max_label_len = len(text)\n",
    "            training_txt.append(text)\n",
    "            train_label_length.append(len(text))\n",
    "            train_input_length.append(img.shape[1]-1)\n",
    "        train_padded_txt = pad_sequences(training_txt, padding='post', maxlen=51)\n",
    "\n",
    "        yield np.array(training_img), np.array(train_padded_txt), np.array(train_input_length), np.array(train_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_gen(instrument):\n",
    "    path_x = f'D:/AMT/all/batches/{instrument}/validate_x'\n",
    "    path_y = f'D:/AMT/all/batches/{instrument}/validate_y'\n",
    "    for idx, dirname in enumerate(os.listdir(path_x)):\n",
    "        validate_img = []\n",
    "        validate_txt = []\n",
    "        validate_input_length = []\n",
    "        validate_label_length = []\n",
    "        # max_label_len = 0\n",
    "        for filename in os.listdir(f'{path_x}/{dirname}'):\n",
    "            # Images\n",
    "            img = cv2.imread(f'{path_x}/{dirname}/{filename}', cv2.IMREAD_GRAYSCALE)\n",
    "            # img = img.reshape(img.shape[1], img.shape[0])\n",
    "            # (W, H) --> (W, H, 1)\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            # Normalize image\n",
    "            img = img / 255.\n",
    "            validate_img.append(img)\n",
    "\n",
    "            # Text Targets\n",
    "            text = np.load(f'{path_y}/{dirname}/{filename}'.split('.')[0] + '.npy')\n",
    "            # if len(text) > max_label_len:\n",
    "            #     max_label_len = len(text)\n",
    "            validate_txt.append(text)\n",
    "            validate_label_length.append(len(text))\n",
    "            validate_input_length.append(img.shape[1]-1)\n",
    "        validate_padded_txt = pad_sequences(validate_txt, padding='post', maxlen=51)\n",
    "\n",
    "        yield np.array(validate_img), np.array(validate_padded_txt), np.array(validate_input_length), np.array(validate_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i = json.load(open('C:/Users/trifo/Desktop/AMT/w2i_all.json', 'r'))\n",
    "len(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128,None,1))\n",
    "# print(inputs.shape[0]/2)\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 1))(conv_1)\n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 1))(conv_2)\n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "pool_5 = MaxPool2D(pool_size=(2, 1))(conv_5)\n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_5)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(conv_6)\n",
    "conv_7 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_6)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_7)\n",
    "conv_8 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_8)\n",
    "pool_7 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "conv_9 = Conv2D(512, (2,2), activation = 'relu')(pool_7)\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_9)\n",
    " \n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(len(w2i)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, None, 1)]    0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, None, 64)     640       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 64, None, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 64, None, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, None, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, None, 256)     295168    \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 32, None, 256)     590080    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, None, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, None, 512)     1180160   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 8, None, 512)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, None, 512)      2359808   \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, None, 512)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 4, None, 512)      2359808   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, None, 512)     2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 4, None, 512)      2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, None, 512)     2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, None, 512)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, None, 512)      1049088   \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, None, 512)         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 256)        656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 256)        394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 1635)        420195    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,743,331\n",
      "Trainable params: 11,741,283\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_len = 51\n",
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length, )\n",
    " \n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "#model to be used at training time\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 512, 64  640         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 64, 512, 64)  0          ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 512, 128  73856       ['max_pooling2d_6[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 32, 512, 128  0          ['conv2d_10[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 512, 256  295168      ['max_pooling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 512, 256  590080      ['conv2d_11[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 16, 512, 256  0          ['conv2d_12[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 512, 512  1180160     ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 8, 512, 512)  0          ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 512, 512)  2359808     ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 4, 512, 512)  0          ['conv2d_14[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 512, 512)  2359808     ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 512, 512)  2048       ['conv2d_15[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 4, 512, 512)  2359808     ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 512, 512)  2048       ['conv2d_16[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 2, 512, 512)  0          ['batch_normalization_3[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 1, 511, 512)  1049088     ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 511, 512)     0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 511, 256)    656384      ['lambda_1[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 511, 256)    394240      ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 511, 1635)    420195      ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['dense_1[0][0]',                \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,743,331\n",
      "Trainable params: 11,741,283\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.save_weights('my_model_weights.h5')\n",
    "    gen = batch_gen()\n",
    "    next(gen, None)\n",
    "    index = 1\n",
    "    while True:\n",
    "        print(f'Epoch: {i+1} | Batch: {index}')\n",
    "        # print(model.weights)\n",
    "        index +=1\n",
    "        next_batch = next(gen, None)\n",
    "        if not next_batch:\n",
    "            break\n",
    "        training_img, train_padded_txt, train_input_length, train_label_length = next_batch\n",
    "        print(train_input_length)\n",
    "        history = model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = 1, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)\n",
    "        # model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = 1,  verbose = 1, callbacks = callbacks_list)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 19s 19s/step\n",
      "\n",
      "Batch 1 | Shape 1497\n",
      "\n",
      "Accuracy 0.9848\n",
      "Original: note-G4_whole | note-B4_whole | note-C5_whole | note-A4_whole | note-D5_whole | note-B4_whole | note-G4_whole | note-D5_whole | note-E5_whole | note-D5_whole | note-C5_whole | note-C5_whole | note-B4_double_whole | note-A4_double_whole.\n",
      "\n",
      "Predicted: note-G4_whole | note-Bb4_whole | note-C5_whole | note-A4_whole | note-D5_whole | note-Bb4_whole | note-G4_whole | note-D5_whole | note-E5_whole | note-D5_whole | note-C5_whole | note-C5_whole | note-B4_double_whole | note-A4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9125\n",
      "Original: rest-quadruple_whole | rest-quadruple_whole | note-D4_double_whole | note-F4_whole | note-G4_whole | note-D4_half | note-F4_whole | note-E4_quarter | note-D4_quarter | note-D4_whole | note-D4_quarter | note-E4_quarter | note-F4_quarter | note-G4_quarter | note-A4_half | note-Bb4_half.\n",
      "\n",
      "Predicted: rest-quadruple_whole | note-D4_double_whole | note-F4_whole | note-G4_whole | note-D4_half | note-F4_whole | note-E4_quarter | note-D4_quarter | note-D4_whole | note-D4_quarter | note-E4_quarter | note-F4_quarter | note-G4_quarter | note-A4_half | note-B4_half.\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9038\n",
      "Original: rest-quadruple_whole | rest-whole | note-A3_double_whole | note-D3_whole | note-A3_whole | note-G3_half | note-F3_half | note-E3_whole | note-D3_double_whole | rest-whole | rest-half | note-D3_half | note-A3_whole. | note-G3_quarter | note-F3_quarter\n",
      "\n",
      "Predicted: rest-quadruple_whole | note-A3_double_whole | note-D3_whole | note-A3_whole | note-G3_half | note-F3_half | note-E3_whole | note-D3_double_whole | rest-whole | note-D3_half | note-A3_whole | note-G3_quarter | note-F3_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9216\n",
      "Original: rest-quadruple_whole | rest-quadruple_whole | note-F4_whole | note-G4_half. | note-F4_quarter | note-G4_quarter | note-A4_quarter | note-Bb4_whole | note-A4_half | note-G4_whole | note-A4_half | note-A4_half | note-Bb4_half | note-C5_half | note-D5_half | note-C5_quarter | note-Bb4_quarter | note-C5_whole\n",
      "\n",
      "Predicted: rest-quadruple_whole | note-F4_whole | note-G4_half. | note-F4_quarter | note-G4_quarter | note-A4_quarter | note-Bb4_whole | note-A4_half | note-G4_whole | note-A4_half | note-A4_half | note-Bb4_half | note-C5_half | note-D5_half | note-C5_quarter | note-Bb4_quarter | note-C5_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9069\n",
      "Original: note-F3_whole | note-F3_whole | note-G3_whole | note-D3_whole | note-A2_double_whole_fermata | note-F3_whole | note-F3_half | note-F3_half | note-F3_half | note-A3_half | note-G3_whole | note-A3_whole | note-E3_whole | note-E3_whole | note-F3_whole | note-E3_whole | note-D3_double_whole_fermata\n",
      "\n",
      "Predicted: note-F3_whole | note-F3_whole | note-G3_whole | note-D3_whole | note-A2_whole | note-F3_whole | note-F3_half | note-F3_half | note-F3_half | note-A3_half | note-G3_whole | note-A3_whole | note-E3_whole | note-E3_whole | note-F3_whole | note-E3_whole | note-D3_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9012\n",
      "Original: note-E4_whole | note-F4_half | note-C4_half | note-E4_double_whole_fermata | note-A3_whole | note-E4_whole | note-E4_double_whole_fermata | note-F4_whole | note-F4_half | note-F4_half | note-F4_whole | note-F4_whole | note-G4_whole | note-E4_double_whole | note-F4_double_whole_fermata\n",
      "\n",
      "Predicted: note-E4_whole | note-F4_half | note-C4_half | note-E4_double_whole | note-A3_whole | note-E4_whole | note-E4_double_whole | note-F4_whole | note-F4_half | note-F4_half | note-F4_whole | note-F4_whole | note-G4_whole | note-E4_double_whole | note-F4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-E5_double_whole | note-B4_whole | note-C5_whole. | note-C5_half | note-D5_whole | note-E5_double_whole | note-G5_whole | note-E5_double_whole | note-D5_whole | note-C5_whole. | note-C5_half | note-B4_whole | note-G4_whole. | note-G4_half\n",
      "\n",
      "Predicted: note-E5_double_whole | note-B4_whole | note-C5_whole. | note-C5_half | note-D5_whole | note-E5_double_whole | note-G5_whole | note-E5_double_whole | note-D5_whole | note-C5_whole. | note-C5_half | note-B4_whole | note-G4_whole. | note-G4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A4_whole | note-G4_whole | note-F#4_whole | note-F4_whole | note-F4_half | note-F4_half | note-G4_whole | note-G4_half | note-A4_whole | note-G4_half | note-F4_whole | note-G4_whole | note-A4_whole | note-A4_whole | note-Bb4_whole. | note-A4_half | note-G4_whole | note-A4_double_whole\n",
      "\n",
      "Predicted: note-A4_whole | note-G4_whole | note-F#4_whole | note-F4_whole | note-F4_half | note-F4_half | note-G4_whole | note-G4_half | note-A4_whole | note-G4_half | note-F4_whole | note-G4_whole | note-A4_whole | note-A4_whole | note-Bb4_whole. | note-A4_half | note-G4_whole | note-A4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9715\n",
      "Original: note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_whole | note-A4_half | note-A4_half | note-A4_whole | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-G4_whole | note-F4_whole | note-G4_half | note-A4_double_whole | note-G4_double_whole | note-F#4_half | note-G4_double_whole\n",
      "\n",
      "Predicted: note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_whole | note-A4_half | note-A4_half | note-A4_whole | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-A4_half | note-G4_whole | note-F4_whole | note-G4_half | note-A4_whole. | note-G4_double_whole | note-F#4_half | note-G4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A4_whole | note-G4_whole | note-F#4_whole | note-F4_whole | note-F4_half | note-F4_half | note-G4_whole | note-G4_half | note-A4_whole | note-G4_half | note-F4_whole | note-G4_whole | note-A4_whole | note-A4_whole | note-Bb4_whole. | note-A4_half | note-G4_whole | note-A4_double_whole\n",
      "\n",
      "Predicted: note-A4_whole | note-G4_whole | note-F#4_whole | note-F4_whole | note-F4_half | note-F4_half | note-G4_whole | note-G4_half | note-A4_whole | note-G4_half | note-F4_whole | note-G4_whole | note-A4_whole | note-A4_whole | note-Bb4_whole. | note-A4_half | note-G4_whole | note-A4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9503\n",
      "Original: note-A4_whole | note-A4_whole | note-G4_double_whole | note-F4_double_whole | note-G4_double_whole | note-A4_double_whole. | note-G4_whole | note-F4_double_whole | note-E4_whole | note-F4_double_whole_fermata\n",
      "\n",
      "Predicted: note-A4_whole | note-A4_whole | note-G4_double_whole | note-F4_double_whole | note-G4_double_whole | note-A4_double_whole | note-G4_whole | note-F4_double_whole | note-E4_whole | note-F4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9483\n",
      "Original: note-D4_double_whole | note-Bb4_whole | note-G4_half | note-C5_half. | note-C5_quarter | note-Bb4_half | note-A4_whole | note-Bb4_whole | note-G4_whole | rest-whole | rest-half | note-G4_half | note-A4_whole | note-G4_whole | note-A4_whole | note-Bb4_double_whole. | note-A4_whole\n",
      "\n",
      "Predicted: note-D4_double_whole | note-Bb4_whole | note-G4_half | note-C5_half. | note-C5_quarter | note-B4_half | note-A4_whole | note-Bb4_whole | note-G4_whole | rest-whole | note-G4_half | note-A4_whole | note-G4_whole | note-A4_whole | note-B4_double_whole | note-A4_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8551\n",
      "Original: rest-quadruple_whole | rest-quadruple_whole | rest-whole | rest-half | note-G3_whole | note-G3_half | note-F3_whole | note-E3_whole | note-D3_half | note-G3_half. | note-F#3_eighth | note-E3_eighth | note-F#3_half | note-G3_half | note-G2_half. | note-A2_quarter | note-B2_quarter | note-C3_quarter | note-D3_quarter | note-C3_eighth\n",
      "\n",
      "Predicted: rest-quadruple_whole | note-G3_whole | note-G3_half | note-F3_whole | note-E3_whole | note-D3_half | note-G3_half. | note-F#3_eighth | note-E3_eighth | note-F#3_half | note-G3_half | note-G2_half | note-A2_quarter | note-B2_quarter | note-C3_quarter | note-D3_quarter | note-C3_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-F4_whole | note-F4_half | note-G4_half | note-A4_quarter | note-G4_quarter | note-A4_quarter | note-Bb4_quarter | note-C5_whole | note-D5_whole. | note-C5_quarter | note-C5_whole | note-Bb4_half | note-C5_whole | note-A4_whole | note-A4_half | note-A4_half | note-Bb4_quarter | note-A4_quarter | note-Bb4_quarter | note-C5_quarter | note-Bb4_half | note-A4_half | note-G4_half | note-F4_half | note-E4_whole | rest-whole | note-F4_whole | note-F4_half | note-G4_half\n",
      "\n",
      "Predicted: note-F4_whole | note-F4_half | note-G4_half | note-A4_quarter | note-G4_quarter | note-A4_quarter | note-Bb4_quarter | note-C5_whole | note-D5_whole. | note-C5_quarter | note-C5_whole | note-Bb4_half | note-C5_whole | note-A4_whole | note-A4_half | note-A4_half | note-Bb4_quarter | note-A4_quarter | note-Bb4_quarter | note-C5_quarter | note-Bb4_half | note-A4_half | note-G4_half | note-F4_half | note-E4_whole | rest-whole | note-F4_whole | note-F4_half | note-G4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9587\n",
      "Original: rest-quadruple_whole | rest-whole | note-G4_double_whole | note-E4_whole | note-F4_double_whole | note-G4_half. | note-F4_quarter | note-E4_quarter | note-D4_half | note-D4_half. | note-C4_quarter | note-B3_quarter | note-A3_quarter | note-G3_whole | note-F3_whole | note-G3_double_whole\n",
      "\n",
      "Predicted: rest-quadruple_whole | note-G4_double_whole | note-E4_whole | note-F4_double_whole | note-G4_half. | note-F4_quarter | note-E4_quarter | note-D4_half | note-D4_half. | note-C4_quarter | note-B3_quarter | note-A3_quarter | note-G3_whole | note-F3_whole | note-G3_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9000\n",
      "Original: note-A4_half. | note-G4_quarter | note-F4_quarter | note-G4_half | note-A4_whole | note-G4_half | note-A4_quadruple_whole | rest-whole | note-A4_double_whole | note-A4_half | note-A4_half | note-A4_double_whole | note-A4_quadruple_whole\n",
      "\n",
      "Predicted: note-A4_half. | note-G4_quarter | note-F4_quarter | note-G4_half | note-A4_whole | note-G4_half | note-A4_double_whole | note-A4_double_whole | note-A4_half | note-A4_half | note-A4_double_whole | note-A4_double_whole\n",
      "\n",
      "----------------------------------------\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "\n",
      "Batch 2 | Shape 345\n",
      "\n",
      "Accuracy 0.9865\n",
      "Original: rest-quarter | note-D4_quarter | rest-eighth | note-Bb3_eighth | note-Eb4_quarter | note-C4_quarter | rest-eighth | note-A3_eighth | note-D4_quarter | note-Bb3_quarter | rest-eighth | note-G3_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-Bb3_sixteenth | note-A3_sixteenth | note-Bb3_sixteenth | note-G3_sixteenth | note-Bb3_sixteenth | note-C4_sixteenth | note-D4_sixteenth | note-C#4_sixteenth | note-D4_eighth | note-D4_eighth | note-G3_eighth\n",
      "\n",
      "Predicted: rest-quarter | note-D4_quarter | rest-eighth | note-B3_eighth | note-E4_quarter | note-C4_quarter | rest-eighth | note-A3_eighth | note-D4_quarter | note-B3_quarter | rest-eighth | note-G3_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-C4_eighth | note-B3_sixteenth | note-A3_sixteenth | note-B3_sixteenth | note-G3_sixteenth | note-B3_sixteenth | note-C4_sixteenth | note-D4_sixteenth | note-C#4_sixteenth | note-D4_eighth | note-D4_eighth | note-G3_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8780\n",
      "Original: rest-quarter | rest-quarter | note-E4_eighth | note-D4_eighth | note-C4_quarter | note-C4_quarter | note-D4_half | rest-quarter | note-F4_quarter | note-E4_quarter | note-C4_quarter | note-A3_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-E4_half | note-D4_quarter | rest-quarter\n",
      "\n",
      "Predicted: rest-half | note-E4_eighth | note-D4_eighth | note-C4_quarter | note-C4_quarter | note-D4_half | rest-quarter | note-F4_quarter | note-E4_quarter | note-C4_quarter | note-A3_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-E4_half | note-D4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9935\n",
      "Original: note-D5_whole | note-E5_whole | note-F#5_whole | note-G5_eighth | note-D5_eighth | note-C5_eighth | note-B4_eighth | note-A4_eighth | note-G4_eighth | note-F#4_eighth | note-G4_eighth\n",
      "\n",
      "Predicted: note-D5_whole | note-E5_whole | note-F5_whole | note-G5_eighth | note-D5_eighth | note-C5_eighth | note-B4_eighth | note-A4_eighth | note-G4_eighth | note-F#4_eighth | note-G4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-D4_quarter. | note-F#4_eighth | note-D4_quarter. | note-F#4_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-E4_eighth | note-F#4_quarter. | note-A4_eighth | note-F#4_quarter. | note-A4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-G4_eighth\n",
      "\n",
      "Predicted: note-D4_quarter. | note-F#4_eighth | note-D4_quarter. | note-F#4_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-A3_eighth | note-D4_eighth | note-E4_eighth | note-F#4_quarter. | note-A4_eighth | note-F#4_quarter. | note-A4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-D4_eighth | note-F#4_eighth | note-G4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9965\n",
      "Original: note-Bb3_half | note-Eb4_quarter | note-D4_quarter | note-G4_quarter | note-F4_quarter | note-Eb4_quarter | note-D4_quarter | note-C4_quarter | note-C4_eighth | note-Eb4_eighth | note-Eb4_eighth | note-D4_eighth | note-C4_eighth | note-Bb3_eighth | note-Bb3_quarter. | note-C4_eighth | note-Bb3_quarter | note-C4_eighth | note-D4_eighth\n",
      "\n",
      "Predicted: note-Bb3_half | note-Eb4_quarter | note-D4_quarter | note-G4_quarter | note-F4_quarter | note-Eb4_quarter | note-D4_quarter | note-C4_quarter | note-C4_eighth | note-Eb4_eighth | note-Eb4_eighth | note-D4_eighth | note-C4_eighth | note-Bb3_eighth | note-Bb3_quarter. | note-C4_eighth | note-B3_quarter | note-C4_eighth | note-D4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9213\n",
      "Original: note-Bb4_quarter | note-Eb5_quarter | note-C5_quarter | note-Bb4_quarter | note-Eb5_quarter | note-G5_quarter | note-F5_eighth. | note-Ab5_sixteenth | note-G5_quarter | note-F5_quarter | gracenote-Eb5_eighth | note-D5_half | note-Eb5_quarter | note-C5_quarter | note-Bb4_quarter | note-Eb5_quarter | note-C5_quarter\n",
      "\n",
      "Predicted: note-Bb4_quarter | note-Eb5_quarter | note-C5_quarter | note-Bb4_quarter | note-Eb5_quarter | note-G5_quarter | note-F5_eighth. | note-Ab5_sixteenth | note-G5_quarter | note-F5_quarter | note-D5_half | note-Eb5_quarter | note-C5_quarter | note-B4_quarter | note-Eb5_quarter | note-C5_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8625\n",
      "Original: note-F4_quarter | gracenote-Db5_quarter | note-C5_whole | note-C5_whole | note-F5_eighth | note-C5_eighth | note-C5_half | note-Db5_quarter | note-C5_eighth | note-Bb4_eighth | note-Bb4_half\n",
      "\n",
      "Predicted: note-F4_quarter | note-C5_whole | note-C5_whole | note-F5_eighth | note-C5_eighth | note-C5_half | note-D5_quarter | note-C5_eighth | note-Bb4_eighth | note-Bb4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8933\n",
      "Original: multirest-6 | rest-half | rest-quarter | note-B4_eighth | note-B4_eighth | note-C5_quarter | note-E5_half | note-D5_eighth. | note-C5_sixteenth | note-D5_quarter | note-F5_half | note-E5_eighth. | note-E5_sixteenth\n",
      "\n",
      "Predicted: rest-quarter | rest-quarter | note-Bb4_eighth | note-Bb4_eighth | note-C5_quarter | note-Eb5_half | note-D5_eighth. | note-C5_sixteenth | note-D5_quarter | note-F5_half | note-Eb5_eighth. | note-Eb5_sixteenth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9886\n",
      "Original: note-C6_half | note-Bb5_quarter. | note-Bb5_eighth | note-Ab5_half | note-G5_quarter. | note-G5_eighth | note-F5_half | note-Bb5_quarter. | note-Bb5_eighth | note-Ab5_half | note-Bb5_quarter. | note-Bb5_eighth\n",
      "\n",
      "Predicted: note-C6_half | note-Bb5_quarter. | note-Bb5_eighth | note-A5_half | note-G5_quarter. | note-G5_eighth | note-F5_half | note-Bb5_quarter. | note-Bb5_eighth | note-A5_half | note-Bb5_quarter. | note-Bb5_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-F4_quarter | note-C4_quarter | note-F4_quarter | note-A4_quarter | note-Bb4_quarter | note-G4_quarter | note-E4_quarter | note-C4_quarter | note-F4_quarter | note-C4_quarter | note-F4_quarter | note-A4_quarter | note-Bb4_quarter | note-G4_quarter | note-E4_quarter | note-C4_quarter\n",
      "\n",
      "Predicted: note-F4_quarter | note-C4_quarter | note-F4_quarter | note-A4_quarter | note-Bb4_quarter | note-G4_quarter | note-E4_quarter | note-C4_quarter | note-F4_quarter | note-C4_quarter | note-F4_quarter | note-A4_quarter | note-Bb4_quarter | note-G4_quarter | note-E4_quarter | note-C4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9899\n",
      "Original: note-D5_half | note-A4_half | note-B4_eighth | note-B5_eighth | note-B5_half | note-C#5_quarter | note-E5_eighth | note-D5_eighth | note-F#5_eighth | note-D5_eighth | note-A4_half | note-B4_eighth | note-B5_eighth | note-B5_quarter. | note-A5_sixteenth | note-G5_sixteenth | note-F#5_sixteenth | note-E5_sixteenth | note-D5_sixteenth | note-C#5_sixteenth\n",
      "\n",
      "Predicted: note-D5_half | note-A4_half | note-B4_eighth | note-B5_eighth | note-Bb5_half | note-C#5_quarter | note-E5_eighth | note-D5_eighth | note-F#5_eighth | note-D5_eighth | note-A4_half | note-B4_eighth | note-B5_eighth | note-Bb5_quarter. | note-A5_sixteenth | note-G5_sixteenth | note-F#5_sixteenth | note-E5_sixteenth | note-D5_sixteenth | note-C5_sixteenth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9622\n",
      "Original: note-D5_half | note-D5_quarter. | note-D5_eighth | note-D5_quarter | note-A4_quarter | rest-quarter | rest-eighth | note-A4_eighth | note-D5_eighth | note-F#5_eighth | note-A5_eighth | note-F#5_eighth | note-G5_eighth | note-E5_eighth | note-C#5_eighth | note-A4_eighth | note-D5_quarter | note-A4_quarter | rest-quarter | rest-eighth | note-A4_eighth\n",
      "\n",
      "Predicted: note-D5_half | note-D5_quarter. | note-D5_eighth | note-D5_quarter | note-A4_quarter | rest-quarter | rest-eighth | note-A4_eighth | note-D5_eighth | note-F#5_eighth | note-A5_eighth | note-F#5_eighth | note-G5_eighth | note-E5_eighth | note-C#5_eighth | note-A4_eighth | note-D5_quarter | note-A4_quarter | rest-quarter | note-A4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-G4_quarter. | note-A4_sixteenth | note-G4_sixteenth | note-F#4_quarter | note-E4_quarter | note-B4_half | note-A#4_quarter | note-A4_quarter | note-G4_quarter. | note-A4_sixteenth | note-G4_sixteenth | note-F#4_quarter | note-E4_quarter | note-A4_half | note-G#4_quarter | note-A4_quarter\n",
      "\n",
      "Predicted: note-G4_quarter. | note-A4_sixteenth | note-G4_sixteenth | note-F#4_quarter | note-E4_quarter | note-B4_half | note-A#4_quarter | note-A4_quarter | note-G4_quarter. | note-A4_sixteenth | note-G4_sixteenth | note-F#4_quarter | note-E4_quarter | note-A4_half | note-G#4_quarter | note-A4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-C4_quarter | rest-quarter | rest-eighth | note-C4_eighth | note-B3_eighth | note-C4_eighth | note-D4_quarter | rest-quarter | rest-eighth | note-D4_eighth | note-C4_eighth | note-D4_eighth | note-E4_quarter | rest-quarter | rest-eighth | note-E4_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-G4_eighth | note-F4_eighth | note-E4_eighth | note-D4_eighth\n",
      "\n",
      "Predicted: note-C4_quarter | rest-quarter | rest-eighth | note-C4_eighth | note-B3_eighth | note-C4_eighth | note-D4_quarter | rest-quarter | rest-eighth | note-D4_eighth | note-C4_eighth | note-D4_eighth | note-E4_quarter | rest-quarter | rest-eighth | note-E4_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-D4_eighth | note-E4_eighth | note-F4_eighth | note-G4_eighth | note-F4_eighth | note-E4_eighth | note-D4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9544\n",
      "Original: note-F4_quarter | rest-eighth | note-F4_eighth | note-G4_quarter | rest-eighth | note-G4_eighth | note-A4_half | rest-quarter | rest-eighth | note-C4_eighth | note-F4_quarter. | note-F4_eighth | note-G4_quarter. | note-A4_eighth | note-G4_half | note-F4_quarter | rest-eighth | note-F4_eighth\n",
      "\n",
      "Predicted: note-F4_quarter | rest-eighth | note-F4_eighth | note-G4_quarter | rest-eighth | note-G4_eighth | note-A4_half | rest-quarter | note-C4_eighth | note-F4_quarter. | note-F4_eighth | note-G4_quarter. | note-A4_eighth | note-G4_half | note-F4_quarter | rest-eighth | note-F4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A5_half | note-A5_quarter | note-A5_quarter | note-F#5_quarter | note-D5_quarter | rest-quarter | note-A5_quarter | note-F#5_quarter | note-D5_quarter | note-D6_half | note-C#6_quarter | note-F#5_quarter | note-B5_half\n",
      "\n",
      "Predicted: note-A5_half | note-A5_quarter | note-A5_quarter | note-F#5_quarter | note-D5_quarter | rest-quarter | note-A5_quarter | note-F#5_quarter | note-D5_quarter | note-D6_half | note-C#6_quarter | note-F#5_quarter | note-B5_half\n",
      "\n",
      "----------------------------------------\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "\n",
      "Batch 3 | Shape 517\n",
      "\n",
      "Accuracy 0.9852\n",
      "Original: rest-half | note-B3_half | note-D4_half | note-E4_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-F4_quarter | note-E4_quarter | note-D4_quarter | note-E4_half | note-D4_quarter | note-G4_whole | note-F#4_half | note-G4_half\n",
      "\n",
      "Predicted: rest-half | note-Bb3_half | note-D4_half | note-Eb4_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-F4_quarter | note-Eb4_quarter | note-D4_quarter | note-E4_half | note-D4_quarter | note-G4_whole | note-F#4_half | note-G4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9397\n",
      "Original: note-F3_half | note-G3_quarter | note-E3_quarter | note-F3_quarter. | note-G3_eighth | note-C3_quarter | note-C4_quarter | note-A4_half | note-G4_half | note-F4_half | rest-half | rest-quarter | note-C4_quarter | note-A4_half | note-F4_whole\n",
      "\n",
      "Predicted: note-F3_half | note-G3_quarter | note-E3_quarter | note-F3_quarter. | note-G3_eighth | note-C3_quarter | note-C4_quarter | note-A4_half | note-G4_half | note-F4_half | rest-half | note-C4_quarter | note-A4_half | note-F4_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8758\n",
      "Original: multirest-9 | rest-half | rest-quarter | note-G4_quarter | note-C5_half | note-C5_half | note-C5_half | note-C5_quarter | note-C5_quarter | note-G5_half | note-D5_half | note-E5_half | note-C5_half\n",
      "\n",
      "Predicted: rest-quarter | note-G4_quarter | note-C5_half | note-C5_half | note-C5_half | note-C5_quarter | note-C5_quarter | note-G5_half | note-D5_half | note-E5_half | note-C5_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8758\n",
      "Original: multirest-9 | rest-half | rest-quarter | note-G4_quarter | note-C5_half | note-C5_half | note-C5_half | note-C5_quarter | note-C5_quarter | note-G5_half | note-D5_half | note-E5_half | note-C5_half\n",
      "\n",
      "Predicted: rest-quarter | note-G4_quarter | note-C5_half | note-C5_half | note-C5_half | note-C5_quarter | note-C5_quarter | note-G5_half | note-D5_half | note-E5_half | note-C5_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.7148\n",
      "Original: multirest-10 | rest-half | rest-quarter | rest-eighth_fermata | note-Bb4_eighth | note-Bb4_quarter. | note-G4_eighth | note-Eb4_quarter | rest-eighth | note-Eb5_eighth | gracenote-Eb5_quarter | note-D5_half | rest-quarter | rest-eighth | note-C5_eighth | gracenote-C5_quarter | note-Bb4_half | rest-quarter | rest-eighth | note-Ab4_eighth | note-G4_half | note-F4_half\n",
      "\n",
      "Predicted: rest-eighth | rest-quarter | note-B4_eighth | note-Bb4_quarter. | note-G4_eighth | note-Eb4_quarter | rest-eighth | note-Eb5_eighth | note-D5_half | rest-quarter | note-C5_eighth | note-Bb4_half | rest-quarter | rest-eighth | note-A4_eighth | note-G4_half | note-F4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A3_half | note-E3_half | note-C3_quarter | note-A2_quarter | note-E3_half | note-C3_quarter | note-D3_quarter | note-E3_quarter | note-F3_quarter | note-G3_half | note-C3_half | note-E3_half | note-G#3_quarter | note-A3_quarter | note-B3_half | note-E3_half\n",
      "\n",
      "Predicted: note-A3_half | note-E3_half | note-C3_quarter | note-A2_quarter | note-E3_half | note-C3_quarter | note-D3_quarter | note-E3_quarter | note-F3_quarter | note-G3_half | note-C3_half | note-E3_half | note-G#3_quarter | note-A3_quarter | note-B3_half | note-E3_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9839\n",
      "Original: note-D3_half | note-D3_quarter | note-D3_quarter | note-D3_half. | note-D3_quarter | note-D3_quarter. | note-Bb2_eighth | note-C3_quarter | note-D3_quarter | note-G2_half. | note-G2_quarter | note-D3_quarter. | note-Bb2_eighth | note-C3_quarter | note-D3_quarter | note-G2_half. | note-Bb2_quarter\n",
      "\n",
      "Predicted: note-D3_half | note-D3_quarter | note-D3_quarter | note-D3_half. | note-D3_quarter | note-D3_quarter. | note-B2_eighth | note-C3_quarter | note-D3_quarter | note-G2_half | note-G2_quarter | note-D3_quarter. | note-B2_eighth | note-C3_quarter | note-D3_quarter | note-G2_half | note-Bb2_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-G4_whole | note-E4_whole | note-A4_half. | note-G4_quarter | note-F4_half | note-E4_half | note-D4_whole | note-C4_whole\n",
      "\n",
      "Predicted: note-G4_whole | note-E4_whole | note-A4_half. | note-G4_quarter | note-F4_half | note-E4_half | note-D4_whole | note-C4_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9383\n",
      "Original: multirest-5 | note-D5_quarter. | note-A4_eighth | note-A4_quarter | rest-quarter | multirest-5 | note-D5_quarter. | note-A4_eighth | note-A4_quarter | rest-quarter | note-D5_whole | note-E5_whole\n",
      "\n",
      "Predicted: multirest-1 | note-D5_quarter. | note-A4_eighth | note-A4_quarter | rest-quarter | rest-half | note-D5_quarter. | note-A4_eighth | note-A4_quarter | rest-quarter | note-D5_whole | note-E5_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9850\n",
      "Original: rest-half | note-A4_half | note-B4_half | note-A4_whole | note-G4_half | rest-half | note-F#4_half | note-E4_half | note-F#4_half. | note-E4_quarter | note-D4_half\n",
      "\n",
      "Predicted: rest-half | note-A4_half | note-B4_half | note-A4_whole | note-G4_half | rest-half | note-F4_half | note-E4_half | note-F4_half. | note-E4_quarter | note-D4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9767\n",
      "Original: note-G3_half | note-G3_half | note-C4_whole | note-Bb3_half | note-Bb3_half | note-Eb4_half | note-C4_half | note-D4_half. | note-D4_quarter | note-G3_whole\n",
      "\n",
      "Predicted: note-G3_half | note-G3_half | note-C4_whole | note-B3_half | note-B3_half | note-E4_half | note-C4_half | note-D4_half. | note-D4_quarter | note-G3_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-C4_half | note-E4_half | note-E4_half | note-D4_half | note-C4_half | note-E4_half | note-E4_half | note-A4_half | note-G4_quarter | note-F4_half | note-F4_quarter | note-E4_whole\n",
      "\n",
      "Predicted: note-C4_half | note-E4_half | note-E4_half | note-D4_half | note-C4_half | note-E4_half | note-E4_half | note-A4_half | note-G4_quarter | note-F4_half | note-F4_quarter | note-E4_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9773\n",
      "Original: note-C3_quarter | note-C3_half | note-G3_quarter | note-G2_half | note-D3_quarter | note-D3_half | note-A3_quarter | note-A2_half | note-F3_quarter | note-F3_half | note-C4_half | note-C3_quarter | note-F3_quarter | note-G3_quarter | note-G2_quarter | note-C2_half.\n",
      "\n",
      "Predicted: note-C3_quarter | note-C3_half | note-G3_quarter | note-G2_half | note-D3_quarter | note-D3_half | note-A3_quarter | note-A2_half | note-F3_quarter | note-F3_half | note-C4_half | note-C3_quarter | note-F3_quarter | note-G3_quarter | note-G2_quarter | note-G2_whole\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9619\n",
      "Original: note-G3_half. | note-F#3_half. | note-E3_half. | note-D3_half. | note-B2_half. | note-C3_half. | note-D3_half. | note-G2_half.\n",
      "\n",
      "Predicted: note-G3_half. | note-F3_half. | note-E3_half. | note-D3_half. | note-Bb2_half | note-C3_half. | note-D3_half. | note-G2_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8937\n",
      "Original: multirest-1 | note-E4_quarter | note-F#4_quarter | note-G#4_quarter | note-E4_quarter | note-A4_whole | note-G#4_half | note-A4_half | note-B4_quarter | rest-quarter | rest-half | note-C5_quarter | note-D5_quarter | note-E5_quarter | note-C5_quarter\n",
      "\n",
      "Predicted: rest-half | note-E4_quarter | note-F#4_quarter | note-G#4_quarter | note-E4_quarter | note-A4_whole | note-G#4_half | note-A4_half | note-B4_quarter | rest-half | note-C#5_quarter | note-D5_quarter | note-E5_quarter | note-C5_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9840\n",
      "Original: note-G5_whole | note-G5_whole | note-A5_whole | note-F#5_whole | note-G5_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-F#4_eighth | note-E4_eighth | note-F#4_quarter | note-D4_quarter\n",
      "\n",
      "Predicted: note-G5_whole | note-G5_whole | note-A5_whole | note-F5_whole | note-G5_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-G4_quarter | note-F4_eighth | note-E4_eighth | note-F4_quarter | note-D4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Batch 4 | Shape 173\n",
      "\n",
      "Accuracy 0.9107\n",
      "Original: note-Eb5_quarter | note-Bb4_quarter | note-G4_quarter | note-F4_quarter. | note-Ab4_eighth | note-Ab4_eighth | note-C5_eighth | note-Bb4_eighth. | note-Ab4_sixteenth | note-G4_quarter | rest-quarter\n",
      "\n",
      "Predicted: note-E5_quarter | note-B4_quarter | note-G4_quarter | note-F4_quarter. | note-Ab4_eighth | note-A4_eighth | note-C5_eighth | note-Bb4_eighth. | note-Ab4_sixteenth | note-G4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9913\n",
      "Original: note-Bb4_half | note-Eb5_quarter | note-Eb5_eighth. | note-F5_sixteenth | note-D5_quarter | rest-quarter | note-Bb4_sixteenth | note-C5_sixteenth | note-Bb4_sixteenth | note-A4_sixteenth | note-Bb4_sixteenth | note-C5_sixteenth | note-D5_sixteenth | note-Eb5_sixteenth\n",
      "\n",
      "Predicted: note-Bb4_half | note-Eb5_quarter | note-E5_eighth. | note-F5_sixteenth | note-D5_quarter | rest-quarter | note-Bb4_sixteenth | note-C5_sixteenth | note-Bb4_sixteenth | note-Ab4_sixteenth | note-Bb4_sixteenth | note-C5_sixteenth | note-D5_sixteenth | note-Eb5_sixteenth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8968\n",
      "Original: multirest-10 | note-Bb3_half | note-C4_sixteenth | note-Bb3_sixteenth | note-G3_sixteenth | note-Eb3_sixteenth | note-Eb3_eighth. | note-F3_sixteenth | note-D3_quarter | rest-quarter\n",
      "\n",
      "Predicted: multirest-4 | note-Bb3_half | note-C4_sixteenth | note-Bb3_sixteenth | note-G3_sixteenth | note-E3_sixteenth | note-E3_eighth. | note-F3_sixteenth | note-D3_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9204\n",
      "Original: note-A4_quarter | note-F#4_quarter | note-B4_quarter | note-C#5_quarter | note-D5_quarter | note-D5_quarter | note-C#5_half_fermata\n",
      "\n",
      "Predicted: note-A4_quarter | note-F4_quarter | note-B4_quarter | note-C#5_quarter | note-D5_quarter | note-D5_quarter | note-C#5_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-D4_quarter | rest-eighth | note-F#4_eighth | note-F#4_eighth | note-D4_eighth | note-D4_eighth | note-F#4_eighth | note-F#4_eighth | note-A4_eighth | rest-eighth | note-A4_eighth | note-A4_eighth | note-D5_eighth | rest-eighth | note-F#4_eighth\n",
      "\n",
      "Predicted: note-D4_quarter | rest-eighth | note-F#4_eighth | note-F#4_eighth | note-D4_eighth | note-D4_eighth | note-F#4_eighth | note-F#4_eighth | note-A4_eighth | rest-eighth | note-A4_eighth | note-A4_eighth | note-D5_eighth | rest-eighth | note-F#4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8094\n",
      "Original: rest-eighth | multirest-14 | rest-eighth | rest-eighth | note-G4_eighth | note-D5_quarter | note-E5_sixteenth | note-B4_sixteenth | gracenote-B4_eighth | note-C5_quarter | note-D5_sixteenth | note-A4_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-D5_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-A4_sixteenth\n",
      "\n",
      "Predicted: multirest-4 | note-G4_eighth | note-D5_quarter | note-E5_sixteenth | note-B4_sixteenth | note-C5_quarter | note-D5_sixteenth | note-A4_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-D5_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-A4_sixteenth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8640\n",
      "Original: rest-eighth | multirest-22 | rest-quarter | rest-eighth | note-E5_eighth | note-A5_sixteenth | note-G#5_sixteenth | note-F#5_sixteenth | note-E5_sixteenth | note-D5_sixteenth | note-C#5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-B4_eighth. | note-C#5_thirty_second | note-D5_thirty_second | note-C#5_eighth\n",
      "\n",
      "Predicted: multirest-4 | note-E5_eighth | note-A5_sixteenth | note-G5_sixteenth | note-F#5_sixteenth | note-E5_sixteenth | note-D5_sixteenth | note-C#5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-B4_eighth. | note-C#5_thirty_second | note-D5_thirty_second | note-C#5_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8785\n",
      "Original: rest-eighth | multirest-17 | rest-quarter | rest-eighth | note-G5_sixteenth | note-D5_sixteenth | note-D5_sixteenth | note-C5_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-G4_sixteenth | note-F#4_sixteenth | note-G4_eighth. | note-A4_thirty_second | note-B4_thirty_second | note-A4_eighth\n",
      "\n",
      "Predicted: multirest-1 | note-G5_sixteenth | note-D5_sixteenth | note-D5_sixteenth | note-C5_sixteenth | note-C5_sixteenth | note-B4_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-G4_sixteenth | note-F#4_sixteenth | note-G4_eighth. | note-A4_thirty_second | note-B4_thirty_second | note-A4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8762\n",
      "Original: rest-quarter | multirest-13 | rest-quarter | note-E5_eighth | note-E5_eighth | note-A5_eighth | note-E5_eighth | note-D5_sixteenth | note-C#5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-B4_sixteenth | note-D5_sixteenth | note-C#5_eighth\n",
      "\n",
      "Predicted: multirest-4 | note-E5_eighth | note-E5_eighth | note-A5_eighth | note-E5_eighth | note-D5_sixteenth | note-C#5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-B4_sixteenth | note-D5_sixteenth | note-C#5_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.8414\n",
      "Original: rest-eighth | multirest-31 | rest-quarter | rest-eighth | note-D5_eighth | note-G5_eighth | note-D5_eighth | note-C5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-G4_sixteenth | note-C5_eighth. | note-D5_thirty_second | note-E5_thirty_second | note-D5_eighth\n",
      "\n",
      "Predicted: multirest-4 | note-D5_eighth | note-G5_eighth | note-D5_eighth | note-C5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-G4_sixteenth | note-C5_eighth. | note-D5_thirty_second | note-E5_thirty_second | note-D5_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9362\n",
      "Original: multirest-32 | note-G4_quarter | note-B4_eighth | note-A4_eighth | note-A4_quarter | note-C5_eighth | note-B4_eighth | note-B4_quarter | note-D5_eighth | note-C5_eighth\n",
      "\n",
      "Predicted: rest-half | note-G4_quarter | note-B4_eighth | note-A4_eighth | note-A4_quarter | note-C5_eighth | note-B4_eighth | note-B4_quarter | note-D5_eighth | note-C5_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9929\n",
      "Original: note-B4_quarter | note-B4_eighth | note-C5_eighth | note-D5_quarter | note-D5_quarter | note-C5_eighth | note-E5_eighth | note-D5_eighth | note-C5_eighth | note-B4_half\n",
      "\n",
      "Predicted: note-B4_quarter | note-B4_eighth | note-C5_eighth | note-D5_quarter | note-D5_quarter | note-C5_eighth | note-Eb5_eighth | note-D5_eighth | note-C5_eighth | note-B4_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A4_quarter | note-A4_quarter | note-C#5_eighth. | note-C#5_sixteenth | note-C#5_quarter | note-E5_quarter | note-E5_quarter | note-A5_half\n",
      "\n",
      "Predicted: note-A4_quarter | note-A4_quarter | note-C#5_eighth. | note-C#5_sixteenth | note-C#5_quarter | note-E5_quarter | note-E5_quarter | note-A5_half\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-Bb4_quarter | note-Bb4_half | note-C5_eighth | note-D5_eighth | note-Eb5_quarter | note-Eb5_half | note-C5_eighth | note-Bb4_eighth\n",
      "\n",
      "Predicted: note-Bb4_quarter | note-Bb4_half | note-C5_eighth | note-D5_eighth | note-Eb5_quarter | note-Eb5_half | note-C5_eighth | note-Bb4_eighth\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 1.0000\n",
      "Original: note-A4_half | note-C#5_half | note-E5_eighth | note-D#5_eighth | note-E5_eighth | note-C#5_eighth | note-A4_quarter | note-A4_quarter\n",
      "\n",
      "Predicted: note-A4_half | note-C#5_half | note-E5_eighth | note-D#5_eighth | note-E5_eighth | note-C#5_eighth | note-A4_quarter | note-A4_quarter\n",
      "\n",
      "----------------------------------------\n",
      "Accuracy 0.9553\n",
      "Original: note-Eb5_sixteenth | note-Eb4_sixteenth | note-F4_sixteenth | note-G4_sixteenth | note-Ab4_sixteenth | note-Bb4_sixteenth | note-C5_sixteenth | note-D5_sixteenth | note-Eb5_sixteenth | note-Eb4_sixteenth | note-F4_sixteenth | note-G4_sixteenth | note-Ab4_sixteenth | note-Bb4_sixteenth | note-C5_sixteenth | note-D5_sixteenth | note-Eb5_sixteenth | note-G5_sixteenth | note-F5_sixteenth | note-Eb5_sixteenth | note-D5_sixteenth | note-C5_sixteenth | note-Bb4_sixteenth | note-Ab4_sixteenth | note-G4_sixteenth | note-Eb4_sixteenth | note-F4_sixteenth | note-G4_sixteenth | note-Ab4_sixteenth | note-Bb4_sixteenth | note-C5_sixteenth | note-D5_sixteenth\n",
      "\n",
      "Predicted: note-E5_sixteenth | note-E4_sixteenth | note-F#4_sixteenth | note-G4_sixteenth | note-Ab4_sixteenth | note-B4_sixteenth | note-C#5_sixteenth | note-D5_sixteenth | note-E5_sixteenth | note-E4_sixteenth | note-F#4_sixteenth | note-G#4_sixteenth | note-A4_sixteenth | note-B4_sixteenth | note-C#5_sixteenth | note-D5_sixteenth | note-E5_sixteenth | note-G5_sixteenth | note-F#5_sixteenth | note-E5_sixteenth | note-D5_sixteenth | note-C#5_sixteenth | note-B4_sixteenth | note-A4_sixteenth | note-G#4_sixteenth | note-E4_sixteenth | note-F#4_sixteenth | note-G#4_sixteenth | note-A4_sixteenth | note-B4_sixteenth | note-C#5_sixteenth | note-D5_sixteenth\n",
      "\n",
      "----------------------------------------\n",
      "piano mean accuracy: 0.9454\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import distance\n",
    "instrument = 'piano'\n",
    "val = val_gen(instrument)\n",
    "#{instrument}.h5'\n",
    "act_model.load_weights(f'model/{instrument}.h5')\n",
    "i2w = json.load(open('i2w_all.json'))\n",
    "# predict outputs on validation images\n",
    "metric = []\n",
    "for i in range(4):\n",
    "    valid_img, valid_padded_txt, _, _ = next(val)\n",
    "    prediction = act_model.predict(valid_img[:])\n",
    "    print(f\"\\nBatch {i+1} | Shape {valid_img.shape[2]}\\n\")\n",
    "    \n",
    "    # use CTC decoder\n",
    "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], beam_width=500,\n",
    "                            greedy=True)[0][0])\n",
    "    for idx, x in enumerate(out):\n",
    "        og = ''.join([i2w[str(y)] for y in valid_padded_txt[idx] if y != 0])\n",
    "        pred = ''.join([i2w[str(y)] for y in x if int(y) != -1])\n",
    "        accuracy = 1 - distance(og, pred)/len(og)\n",
    "        print(f'Accuracy {accuracy:.4f}')\n",
    "        metric.append(accuracy)\n",
    "        og = ' | '.join([i2w[str(y)] for y in valid_padded_txt[idx] if y != 0])\n",
    "        print(f\"Original: {og}\\n\")\n",
    "        pred = ' | '.join([i2w[str(y)] for y in x if y != -1])\n",
    "        print(f\"Predicted: {pred}\\n\")\n",
    "        print('----------------------------------------')\n",
    "print(f\"{instrument} mean accuracy: {np.mean(metric):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acoustic_guitar mean accuracy: 0.9373\n",
    "marimba mean accuracy: 0.9360 Works better overall, one bad example\n",
    "recorder mean accuracy: 0.8869\n",
    "electric_bass mean accuracy: 0.6174\n",
    "piano mean accuracy: 0.9454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "predicted text = note-F#4_quarter, note-E4_quarter, note-Bb3_eighth, note-E4_eighth, note-G4_eighth, note-Eb4_eighth, note-F4_sixteenth, note-D4_thirty_second, note-F4_thirty_second, note-Ab4_thirty_second, note-F4_sixteenth, note-Eb4_eighth, note-F4_quarter, note-Bb4_quarter, note-Bb3_eighth, note-F4_thirty_second, note-D4_thirty_second, note-E4_sixteenth, note-D4_thirty_second, note-Eb4_eighth, note-F4_sixteenth, note-D4_thirty_second, note-F4_thirty_second, note-Ab4_thirty_second, note-G4_eighth, note-G4_eighth, note-F4_quarter, note-E4_quarter, rest-quarter, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# val = val_gen()\n",
    "act_model.load_weights('model/piano.h5')\n",
    "i2w = json.load(open('i2w_all.json'))\n",
    "# predict outputs on validation images\n",
    "# valid_img, valid_padded_txt, valid_input_length, valid_label_length = next(val)\n",
    "valid_img = cv2.imread('experiment/jojo.png', cv2.IMREAD_GRAYSCALE)\n",
    "# valid_img = valid_img.reshape(1, 128, 388)\n",
    "valid_img = np.expand_dims(valid_img, axis=0)\n",
    "# Normalize image\n",
    "valid_img = valid_img / 255.\n",
    "prediction = act_model.predict(valid_img)\n",
    "# print(f\"\\nFirst batch | Shape {valid_img.shape[2]}\\n\")\n",
    "\n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], beam_width=500,\n",
    "                        greedy=True)[0][0])\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(i2w[str(p)], end = ', ')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efec48cff7f10ec798fbec18b6f2126d2431f377a5414026cc5db74a75ba409b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
